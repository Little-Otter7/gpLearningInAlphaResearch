{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gp learning in alpha research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: import numpy, pandas and gplearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gplearn.functions import make_function\n",
    "\n",
    "# Define custom functions\n",
    "def rank(x):\n",
    "    return pd.Series(x).rank().values\n",
    "\n",
    "def delay(x, d):\n",
    "    \"\"\" Return the array x delayed by d time steps. Handles array inputs for d.\"\"\"\n",
    "    # Ensure d is a scalar even if passed as an array by gplearn\n",
    "    d = int(d[0]) if isinstance(d, np.ndarray) and d.size > 0 else int(d)\n",
    "    \n",
    "    # If delay is zero or negative, return x as is\n",
    "    if d <= 0:\n",
    "        return x\n",
    "    \n",
    "    # If delay is greater than or equal to the length of x, return an array of zeros\n",
    "    if d >= len(x):\n",
    "        return np.zeros_like(x)\n",
    "    \n",
    "    # Otherwise, prepend zeros and truncate the last d elements\n",
    "    return np.concatenate([np.zeros(d), x[:-d]])\n",
    "\n",
    "def correlation(x, y, d):\n",
    "    \"\"\"Computes rolling correlation with protection against non-positive window size.\"\"\"\n",
    "    d = int(np.round(d[0])) if isinstance(d, np.ndarray) and d.size > 0 else int(d)\n",
    "    if d <= 0:\n",
    "        return np.zeros_like(x)  # Return zero correlation if window size is non-positive\n",
    "    else:\n",
    "        return pd.Series(x).rolling(max(d, 1)).corr(pd.Series(y)).fillna(0).values\n",
    "\n",
    "\n",
    "def covariance(x, y, d):\n",
    "    \"\"\"Computes rolling covariance, ensuring non-negative window size.\"\"\"\n",
    "    d = max(int(np.round(d[0])) if isinstance(d, np.ndarray) else int(d), 1)\n",
    "    return pd.Series(x).rolling(d).cov(pd.Series(y)).fillna(0).values\n",
    "\n",
    "def scale(x, a):\n",
    "    \"\"\"Scales the input x by a factor a, normalized by the sum of the absolute values of x.\"\"\"\n",
    "    if np.sum(np.abs(x)) == 0:\n",
    "        return np.zeros_like(x)\n",
    "    return a * x / np.sum(np.abs(x))\n",
    "\n",
    "def delta(x, d):\n",
    "    \"\"\"Computes the difference of x and its delayed version by d steps.\"\"\"\n",
    "    d = max(int(np.round(d[0])) if isinstance(d, np.ndarray) else int(d), 1)\n",
    "    return x - delay(x, d)\n",
    "\n",
    "def signedpower(x, a):\n",
    "    \"\"\"Applies a signed power transformation to x with power a.\"\"\"\n",
    "    return np.sign(x) * (np.abs(x) ** a)\n",
    "\n",
    "def decay_linear(x, d):\n",
    "    \"\"\"Applies a linear decay function over a rolling window of size d.\"\"\"\n",
    "    d = max(int(np.round(d[0])) if isinstance(d, np.ndarray) else int(d), 1)\n",
    "    weights = np.arange(1, d + 1)[::-1]\n",
    "    if len(x) < d:\n",
    "        return np.zeros_like(x)\n",
    "    return pd.Series(x).rolling(window=d).apply(lambda x: np.dot(x, weights) / weights.sum(), raw=True).values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: make function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gplearn.functions import _Function, make_function\n",
    "\n",
    "# Wrap custom functions for gplearn\n",
    "rank_func = make_function(function=rank, name='rank', arity=1)\n",
    "delay_func = make_function(function=delay, name='delay', arity=2, wrap=False)\n",
    "correlation_func = make_function(function=correlation, name='correlation', arity=3)\n",
    "covariance_func = make_function(function=covariance, name='covariance', arity=3)\n",
    "scale_func = make_function(function=scale, name='scale', arity=2)\n",
    "delta_func = make_function(function=delta, name='delta', arity=2)\n",
    "signedpower_func = make_function(function=signedpower, name='signedpower', arity=2)\n",
    "decay_linear_func = make_function(function=decay_linear, name='decay_linear', arity=2)\n",
    "# Create a function set\n",
    "function_set = [\n",
    "    rank_func,\n",
    "    delay_func,\n",
    "    correlation_func,\n",
    "    covariance_func,\n",
    "    scale_func,\n",
    "    delta_func,\n",
    "    signedpower_func,\n",
    "    decay_linear_func,\n",
    "    # Add other custom functions as needed\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test of the Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试数据\n",
    "x = np.random.rand(100)\n",
    "y = np.random.rand(100)\n",
    "d = -5  # 非法的 d 值\n",
    "\n",
    "# 测试 covariance 函数\n",
    "print(\"Covariance with d = -5:\", covariance(x, y, d))\n",
    "\n",
    "d = 5  # 合法的 d 值\n",
    "print(\"Covariance with d = 5:\", covariance(x, y, d))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: preprocess of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process of dataset\n",
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath, parse_dates=True, index_col='Date')\n",
    "    return data\n",
    "\n",
    "def filter_st_pt(data, stock_type_column='StockType'):\n",
    "    return data[~data[stock_type_column].isin(['ST', 'PT'])]\n",
    "\n",
    "def handle_missing_values(data, method='drop'):\n",
    "    if method == 'drop':\n",
    "        return data.dropna()\n",
    "    elif method == 'fill':\n",
    "        return data.fillna(method='ffill')  # 前向填充\n",
    "    return data\n",
    "\n",
    "def restrict_date_range(data, start_date, end_date):\n",
    "    return data.loc[start_date:end_date]\n",
    "\n",
    "def prepare_stock_data(filepath, start_date, end_date):\n",
    "    data = load_data(filepath)\n",
    "    data = filter_st_pt(data)\n",
    "    data = handle_missing_values(data)\n",
    "    data = restrict_date_range(data, start_date, end_date)\n",
    "    return data\n",
    "\n",
    "# 用VWAP计算目标向量y，此处日频数据考虑1日vwap收益 @27/6/2024\n",
    "\"\"\" \n",
    "data['1d_return_vwap'] = data['vwap'].pct_change(1).shift(-1)\n",
    "data.dropna(inplace=True)\n",
    "print(data[['vwap', '1d_return_vwap']].head())\n",
    " \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Fitness Function (RankIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize_series(series, limits=[0.05, 0.95]):\n",
    "    \"\"\"中位数去极值化，通常使用5%和95%的分位数去极值。\"\"\"\n",
    "    quantiles = series.quantile(limits)\n",
    "    return series.clip(quantiles.iloc[0], quantiles.iloc[1])\n",
    "\n",
    "def neutralize_series(series, by):\n",
    "    \"\"\"中性化处理\"\"\"\n",
    "\n",
    "def standardize_series(series):\n",
    "    \"\"\"将序列标准化，使均值为0，标准差为1。\"\"\"\n",
    "    return (series - series.mean()) / series.std()\n",
    "\n",
    "def compute_rank_ic(factor, returns):\n",
    "    \"\"\"计算因子和收益率的 RankIC\"\"\"\n",
    "    return factor.corr(returns, method='spearman') # 用spearman系数，比Pearson效果好\n",
    "\n",
    "def rank_ic_fitness(estimator, X, y, sample_weight):\n",
    "    \"\"\"\n",
    "    自定义适应度函数，计算 RankIC 作为适应度值。\n",
    "    X 是因子矩阵，y 是收益率矩阵。\n",
    "    \"\"\"\n",
    "    factor_df = pd.DataFrame(X)\n",
    "    returns_df = pd.DataFrame(y)\n",
    "    \n",
    "    # 处理因子\n",
    "    factor_winsorized = factor_df.apply(winsorize_series)\n",
    "    factor_standardized = factor_winsorized.apply(standardize_series)\n",
    "    \n",
    "    rank_ic_values = []\n",
    "    for i in range(factor_standardized.shape[1]):\n",
    "        rank_ic = compute_rank_ic(factor_standardized.iloc[:, i], returns_df.iloc[:, i])\n",
    "        rank_ic_values.append(rank_ic)\n",
    "    \n",
    "    # 取平均 RankIC 作为适应度值\n",
    "    average_rank_ic = np.mean(rank_ic_values)\n",
    "    return average_rank_ic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gplearn.genetic import SymbolicTransformer, _fitness_map\n",
    "from gplearn.functions import make_function\n",
    "\n",
    "# 注册自定义适应度函数\n",
    "_fitness_map['rank_ic'] = rank_ic_fitness\n",
    "\n",
    "# 定义自定义 SymbolicTransformer 类\n",
    "class CustomSymbolicTransformer(SymbolicTransformer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def _evaluate(self, program, X, y, sample_weight):\n",
    "        \"\"\"Evaluate the program on the fitness criterion.\"\"\"\n",
    "        y_pred = self._program.execute(X)\n",
    "        return self._metric(y_pred, y, sample_weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5:Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gplearn.genetic import SymbolicRegressor\n",
    "\n",
    "data = pd.read_csv()\n",
    "# 准备模型输入输出\n",
    "features = data[['open', 'close', 'high', 'low', 'vwap']].dropna()\n",
    "target = data['1d_return_vwap'].dropna()\n",
    "\n",
    "# 确保特征和目标行对齐\n",
    "features, target = features.align(target, join='inner')\n",
    "# Parameters\n",
    "gp = SymbolicRegressor(population_size=1000,\n",
    "                       generations=3,\n",
    "                       tournament_size=20,\n",
    "                       stopping_criteria=0.01,\n",
    "                       function_set=function_set,\n",
    "                       metric='rank_ic',  \n",
    "                       p_crossover=0.4,\n",
    "                       p_subtree_mutation=0.01,\n",
    "                       p_hoist_mutation=0,\n",
    "                       p_point_mutation=0.01,\n",
    "                       p_point_replace=0.4,\n",
    "                       max_samples=0.9,\n",
    "                       verbose=1,\n",
    "                       random_state=0,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.fit(features.values, target.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取最佳公式\n",
    "best_programs = gp._best_programs\n",
    "for program in best_programs:\n",
    "    print(program)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
